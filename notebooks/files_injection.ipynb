{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf0bb7-3a9f-4bb6-9ae2-cd5c540de10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Ensure logs folder exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion_db.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\"\n",
    ")\n",
    "\n",
    "# MySQL connection\n",
    "engine = create_engine(\"mysql+pymysql://root:password@localhost:3306/inventory\")\n",
    "\n",
    "def ingest_db(filepath, table_name, engine, chunksize=50000):\n",
    "    \"\"\"Ingest large CSV into database without data loss\"\"\"\n",
    "    first_chunk = True\n",
    "    total_rows = 0\n",
    "\n",
    "    for chunk in pd.read_csv(filepath, chunksize=chunksize):\n",
    "        chunk.to_sql(\n",
    "            table_name,\n",
    "            con=engine,\n",
    "            if_exists=\"replace\" if first_chunk else \"append\",  # replace once, append later\n",
    "            index=False,\n",
    "            method=\"multi\",\n",
    "            chunksize=chunksize\n",
    "        )\n",
    "        total_rows += len(chunk)\n",
    "        first_chunk = False\n",
    "\n",
    "    return total_rows\n",
    "\n",
    "def load_raw_data():\n",
    "    start = time.time()\n",
    "    data_folder = r\"C:\\Users\\shanm\\Downloads\\vendor performance\\data\"\n",
    "\n",
    "    for file in os.listdir(data_folder):\n",
    "        if file.endswith(\".csv\") and file != \"sales.csv\":  # skip sales (already loaded)\n",
    "            table_name = file[:-4].replace(\" \", \"_\")  # table = file name\n",
    "            filepath = os.path.join(data_folder, file)\n",
    "\n",
    "            logging.info(f\"Attempting to ingest {file} as table {table_name}\")\n",
    "            try:\n",
    "                row_count = ingest_db(filepath, table_name, engine)\n",
    "                logging.info(f\"{table_name} ingested successfully with {row_count} rows\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to ingest {file}: {e}\")\n",
    "\n",
    "    end = time.time()\n",
    "    total_time = (end - start) / 60\n",
    "    logging.info(\"------------- Ingestion Complete -------------\")\n",
    "    logging.info(f\"Total Time Taken: {total_time:.2f} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_raw_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
